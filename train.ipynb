{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ePVSga5E_a-e"
   },
   "source": [
    "# Train a Language Model to Detect Human Values in Arguments\n",
    "\n",
    "The following notebook contains the training-procedure for a single training.\n",
    "The final Model is an ensemble of several such runs. More information can be found in the system description paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25237,
     "status": "ok",
     "timestamp": 1667235617561,
     "user": {
      "displayName": "Daniel Schroter",
      "userId": "14162089145838719475"
     },
     "user_tz": -60
    },
    "id": "f3tx1knExlud",
    "outputId": "e08abd38-93af-466d-a856-e1bff8980834"
   },
   "outputs": [],
   "source": [
    "# if on google colab\n",
    "!pip install -q pytorch-lightning==1.6.4 neptune-client transformers sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10254,
     "status": "ok",
     "timestamp": 1667235627811,
     "user": {
      "displayName": "Daniel Schroter",
      "userId": "14162089145838719475"
     },
     "user_tz": -60
    },
    "id": "y5mj8cpdM_O3",
    "outputId": "d8cefe5e-05ab-4ca4-fa7c-aa25d9f2c024"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dschr\\Coding\\nlp\\human_value_detector_tmp\\human_value_detector\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Global seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from pytorch_lightning.loggers import NeptuneLogger\n",
    "\n",
    "from torchmetrics import AUROC\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, multilabel_confusion_matrix\n",
    "\n",
    "import pickle\n",
    "\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "pl.seed_everything(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "btZjckeJs5j7"
   },
   "source": [
    "If you are training to google colab and want to connect to drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.6.4'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 245,
     "status": "ok",
     "timestamp": 1667235666818,
     "user": {
      "displayName": "Daniel Schroter",
      "userId": "14162089145838719475"
     },
     "user_tz": -60
    },
    "id": "UuJkkr9Mpa3h",
    "outputId": "8e00bb43-f22e-4192-be3e-4ee617634117"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\dschr\\Coding\\nlp\\human_value_detector_tmp\\human_value_detector\\train.ipynb Cell 6\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/dschr/Coding/nlp/human_value_detector_tmp/human_value_detector/train.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/dschr/Coding/nlp/human_value_detector_tmp/human_value_detector/train.ipynb#W5sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m os\u001b[39m.\u001b[39mgetcwd()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/dschr/Coding/nlp/human_value_detector_tmp/human_value_detector/train.ipynb#W5sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgoogle\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcolab\u001b[39;00m \u001b[39mimport\u001b[39;00m drive\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/dschr/Coding/nlp/human_value_detector_tmp/human_value_detector/train.ipynb#W5sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m drive\u001b[39m.\u001b[39mmount(\u001b[39m'\u001b[39m\u001b[39m/content/drive\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17685,
     "status": "ok",
     "timestamp": 1667235684811,
     "user": {
      "displayName": "Daniel Schroter",
      "userId": "14162089145838719475"
     },
     "user_tz": -60
    },
    "id": "QE5P0dCepbkD",
    "outputId": "e41c97be-adda-4154-b24d-413ae994af5a"
   },
   "outputs": [],
   "source": [
    "cd ./drive/MyDrive/human_value/human_values_behind_arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git pull"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Modules\n",
    "We use Pytorch Lightning for the training and therefore import the Lighntning Data and Model Modules...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_modules.BertDataModule import BertDataModule, BertDataset\n",
    "from models.BertFineTunerPl import BertFineTunerPl\n",
    "from weights.weights import INS #Weights for Weighting Loss Function (optional)\n",
    "from toolbox.bert_utils import max_for_thres # Algorithm that chooses threshold that maximizes f1-score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Parameters\n",
    "\n",
    "We define the important params upfront. The object is then logged at neptune.ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARAMS = {\n",
    "    # Language Model and Hyperparameters\n",
    "    \"MODEL_PATH\": 'roberta-base',\n",
    "    \"BATCH_SIZE\": 8,\n",
    "    \"ACCUMULATE_GRAD_BATCHES\": 1,\n",
    "    \"LR\": 2e-5,\n",
    "    \"EPOCHS\": 3,\n",
    "    \"OPTIMIZER\": 'AdamW',\n",
    "    \"DEVICE\": torch.device('cuda' if torch.cuda.is_available() else 'cpu'),\n",
    "    \"NUM_TRAIN_WORKERS\": 4,\n",
    "    \"NUM_VAL_WORKERS\": 4,\n",
    "    \"MAX_TOKEN_COUNT\":165,\n",
    "    \"RANDOM_SEED\": RANDOM_SEED, #Random Seed Selected for this Training Run\n",
    "\n",
    "    # Apply Weights to loss function (optional, the submitted system does not weight the loss function).\n",
    "    \"WEIGHTS\": INS,\n",
    "    \"CRITERION\": [nn.BCEWithLogitsLoss()],\n",
    "    # \"CRITERION\": [nn.BCEWithLogitsLoss(pos_weight=torch.Tensor(INS))], # Optional\n",
    "\n",
    "    # Early Stopping Params\n",
    "    \"PATIENCE\": 3,\n",
    "    \"VAL_CHECK_INTERVAL\": 300,\n",
    "\n",
    "    # The metric we optimize for. Alternative \"custom_f1/Val\" and \"max\"\n",
    "    \"MAX_THRESHOLD_METRIC\": \"custom\", #The f1-score that should maximized (custom = formula for the task evaluation)\n",
    "    \"EARLY_STOPPING_METRIC\": \"avg_val_loss\",\n",
    "    \"EARLY_STOPPING_MODE\": \"min\",\n",
    "\n",
    "    # Additional Dropout or Additional Hidden Layers (Not used for the final submission)\n",
    "    \"DROPOUT\": None, # e.g 0.5 (float)\n",
    "    \"HIDDEN_LAYERS\":None, # Of Shape [(512, nn.ReLU()),...] put size of hidden Layer together with activation function in list\n",
    "\n",
    "    # DATA\n",
    "    \"VALIDATION_SET_SIZE\":500,\n",
    "\n",
    "    \"EMBEDDING\": \"CLS\", # \"CLS + MEAN\" for both. Which information should be used from Bert-Output. CLS Token in Submission.\n",
    "\n",
    "    \"TRAIN_PATH\" : \"./data/data_training_full.csv\", #\n",
    "    \"LEAVE_OUT_DATA_PATH\": \"./data/leave_out_dataset_300.csv\"\n",
    "\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Data Loading\n",
    "Please see the data_generation.ipynb notebook... We create the training-data, and leave-out-datafiles there and save them in the data directory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(PARAMS[\"TRAIN_PATH\"], index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We now get the LABEL_COLUMNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "LABEL_COLUMNS = train_df.columns.tolist()[6:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "For the best-performing submission we used a Leave-Out-Dataset, to determine the optimal threshold that maximizes the f1-score at the end. This dataset is used to determine the best threshold for an ensembled model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "leave_out_df = pd.read_csv(PARAMS[\"LEAVE_OUT_DATA_PATH\"], index_col=0)\n",
    "# train_df, test_df = train_test_split(train_df, test_size=500, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rSQsvaBgoM7F"
   },
   "source": [
    "### Linear Learning Rate Schedule\n",
    "Define Parameters for the Linear Learning Rate Schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "r2ywIz841yni"
   },
   "outputs": [],
   "source": [
    "steps_per_epoch=len(train_df) // PARAMS['BATCH_SIZE']\n",
    "total_training_steps = steps_per_epoch * PARAMS['EPOCHS']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YjV_biJ72ERg"
   },
   "source": [
    "We'll use a fifth of the training steps for warm-up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1667223230416,
     "user": {
      "displayName": "Daniel Schroter",
      "userId": "14162089145838719475"
     },
     "user_tz": -60
    },
    "id": "OSHJ3V47G90d",
    "outputId": "f096a726-b8f3-406a-9078-6ec5780fc3aa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(515, 2577)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "warmup_steps = total_training_steps // 5\n",
    "warmup_steps, total_training_steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Prepare Data Modules for the Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Validation Set for this Run\n",
    "To make use of the total available data, the models in the final ensemble are trained on different train-validation splits..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df = train_test_split(train_df, test_size=PARAMS[\"VALIDATION_SET_SIZE\"], random_state=PARAMS[\"RANDOM_SEED\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Create Tokenizer and Data Module for the Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKENIZER = AutoTokenizer.from_pretrained(PARAMS[\"MODEL_PATH\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_module = BertDataModule(\n",
    "    train_df,\n",
    "    val_df,\n",
    "    tokenizer=TOKENIZER,\n",
    "    params=PARAMS,\n",
    "    label_columns=LABEL_COLUMNS\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = BertFineTunerPl(n_classes=len(LABEL_COLUMNS), params=PARAMS, label_columns=LABEL_COLUMNS, n_training_steps=total_training_steps, n_warmup_steps=warmup_steps)\n",
    "NAME = f\"{PARAMS['MODEL_PATH'].replace('/','-')}-BS_{PARAMS['BATCH_SIZE']}-LR_{PARAMS['LR']}-HL_{PARAMS['HIDDEN_LAYERS']}-DROPOUT_{PARAMS['DROPOUT']}\"\n",
    "RUN_ID = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We use Neptune.ai to log the experiment. This is optional. You need to create a new project and add the project and api key for the neptune logger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'neptune.new.utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\dschr\\Coding\\nlp\\human_value_detector_tmp\\human_value_detector\\train.ipynb Cell 33\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/dschr/Coding/nlp/human_value_detector_tmp/human_value_detector/train.ipynb#X43sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Optional: Log Experiments to Neptune\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/dschr/Coding/nlp/human_value_detector_tmp/human_value_detector/train.ipynb#X43sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m neptune_logger \u001b[39m=\u001b[39m NeptuneLogger(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/dschr/Coding/nlp/human_value_detector_tmp/human_value_detector/train.ipynb#X43sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     project\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mYour Project ID\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m#\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/dschr/Coding/nlp/human_value_detector_tmp/human_value_detector/train.ipynb#X43sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     api_key\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mYour API KEY\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m#\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/dschr/Coding/nlp/human_value_detector_tmp/human_value_detector/train.ipynb#X43sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     log_model_checkpoints\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/dschr/Coding/nlp/human_value_detector_tmp/human_value_detector/train.ipynb#X43sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m )\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/dschr/Coding/nlp/human_value_detector_tmp/human_value_detector/train.ipynb#X43sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m neptune_logger\u001b[39m.\u001b[39;49mlog_hyperparams(PARAMS)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dschr/Coding/nlp/human_value_detector_tmp/human_value_detector/train.ipynb#X43sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m neptune_logger\u001b[39m.\u001b[39mexperiment[\u001b[39m\"\u001b[39m\u001b[39mtrain_size\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mlog(\u001b[39mlen\u001b[39m(train_df))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dschr/Coding/nlp/human_value_detector_tmp/human_value_detector/train.ipynb#X43sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m neptune_logger\u001b[39m.\u001b[39mexperiment[\u001b[39m\"\u001b[39m\u001b[39mval_size\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mlog(\u001b[39mlen\u001b[39m(val_df))\n",
      "File \u001b[1;32mc:\\Users\\dschr\\Coding\\nlp\\human_value_detector_tmp\\human_value_detector\\.venv\\lib\\site-packages\\lightning_utilities\\core\\rank_zero.py:43\u001b[0m, in \u001b[0;36mrank_zero_only.<locals>.wrapped_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mThe `rank_zero_only.rank` needs to be set before use\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     42\u001b[0m \u001b[39mif\u001b[39;00m rank \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m---> 43\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     44\u001b[0m \u001b[39mreturn\u001b[39;00m default\n",
      "File \u001b[1;32mc:\\Users\\dschr\\Coding\\nlp\\human_value_detector_tmp\\human_value_detector\\.venv\\lib\\site-packages\\pytorch_lightning\\loggers\\neptune.py:429\u001b[0m, in \u001b[0;36mNeptuneLogger.log_hyperparams\u001b[1;34m(self, params)\u001b[0m\n\u001b[0;32m    427\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mneptune\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m stringify_unsupported\n\u001b[0;32m    428\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 429\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mneptune\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnew\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m stringify_unsupported\n\u001b[0;32m    431\u001b[0m params \u001b[39m=\u001b[39m _convert_params(params)\n\u001b[0;32m    432\u001b[0m params \u001b[39m=\u001b[39m _sanitize_callable_params(params)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'neptune.new.utils'"
     ]
    }
   ],
   "source": [
    "# Optional: Log Experiments to Neptune\n",
    "\n",
    "neptune_logger = NeptuneLogger(\n",
    "    project=\"Your Project ID\", #\n",
    "    api_key=\"Your API KEY\", #\n",
    "    name=NAME,\n",
    "    tags=[f\"{PARAMS['MODEL_PATH']}\",f\"BS-{PARAMS['BATCH_SIZE']}\",f\"LR-{PARAMS['LR']}\",f\"LR-{PARAMS['HIDDEN_LAYERS']}\"],\n",
    "    log_model_checkpoints=False\n",
    ")\n",
    "neptune_logger.log_hyperparams(PARAMS)\n",
    "\n",
    "neptune_logger.experiment[\"train_size\"].log(len(train_df))\n",
    "neptune_logger.experiment[\"val_size\"].log(len(val_df))\n",
    "RUN_ID = neptune_logger._run_short_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Callbacks and create Pytorch Lightning Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "MisconfigurationException",
     "evalue": "GPUAccelerator can not run on your system since the accelerator is not available. The following accelerator(s) is available and can be passed into `accelerator` argument of `Trainer`: ['cpu'].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMisconfigurationException\u001b[0m                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\dschr\\Coding\\nlp\\human_value_detector_tmp\\human_value_detector\\train.ipynb Cell 35\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/dschr/Coding/nlp/human_value_detector_tmp/human_value_detector/train.ipynb#X46sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m checkpoint_callback \u001b[39m=\u001b[39m ModelCheckpoint(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/dschr/Coding/nlp/human_value_detector_tmp/human_value_detector/train.ipynb#X46sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     dirpath\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcheckpoints\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/dschr/Coding/nlp/human_value_detector_tmp/human_value_detector/train.ipynb#X46sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     filename\u001b[39m=\u001b[39m (\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mRUN_ID\u001b[39m}\u001b[39;00m\u001b[39m-\u001b[39m\u001b[39m{\u001b[39;00mNAME\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m RUN_ID \u001b[39melse\u001b[39;00m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mNAME\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/dschr/Coding/nlp/human_value_detector_tmp/human_value_detector/train.ipynb#X46sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     mode\u001b[39m=\u001b[39mPARAMS[\u001b[39m\"\u001b[39m\u001b[39mEARLY_STOPPING_MODE\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/dschr/Coding/nlp/human_value_detector_tmp/human_value_detector/train.ipynb#X46sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m )\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/dschr/Coding/nlp/human_value_detector_tmp/human_value_detector/train.ipynb#X46sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m early_stopping_callback \u001b[39m=\u001b[39m EarlyStopping(monitor\u001b[39m=\u001b[39mPARAMS[\u001b[39m\"\u001b[39m\u001b[39mEARLY_STOPPING_METRIC\u001b[39m\u001b[39m\"\u001b[39m], patience\u001b[39m=\u001b[39mPARAMS[\u001b[39m\"\u001b[39m\u001b[39mPATIENCE\u001b[39m\u001b[39m\"\u001b[39m], mode\u001b[39m=\u001b[39mPARAMS[\u001b[39m\"\u001b[39m\u001b[39mEARLY_STOPPING_MODE\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/dschr/Coding/nlp/human_value_detector_tmp/human_value_detector/train.ipynb#X46sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m trainer \u001b[39m=\u001b[39m pl\u001b[39m.\u001b[39;49mTrainer(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dschr/Coding/nlp/human_value_detector_tmp/human_value_detector/train.ipynb#X46sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     logger\u001b[39m=\u001b[39;49m([neptune_logger] \u001b[39mif\u001b[39;49;00m RUN_ID \u001b[39melse\u001b[39;49;00m []),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dschr/Coding/nlp/human_value_detector_tmp/human_value_detector/train.ipynb#X46sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     callbacks\u001b[39m=\u001b[39;49m[checkpoint_callback, early_stopping_callback],\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dschr/Coding/nlp/human_value_detector_tmp/human_value_detector/train.ipynb#X46sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     max_epochs\u001b[39m=\u001b[39;49mPARAMS[\u001b[39m\"\u001b[39;49m\u001b[39mEPOCHS\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dschr/Coding/nlp/human_value_detector_tmp/human_value_detector/train.ipynb#X46sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     \u001b[39m# fast_dev_run=True,\u001b[39;49;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dschr/Coding/nlp/human_value_detector_tmp/human_value_detector/train.ipynb#X46sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     accelerator\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mgpu\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dschr/Coding/nlp/human_value_detector_tmp/human_value_detector/train.ipynb#X46sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     devices\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dschr/Coding/nlp/human_value_detector_tmp/human_value_detector/train.ipynb#X46sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     enable_progress_bar\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dschr/Coding/nlp/human_value_detector_tmp/human_value_detector/train.ipynb#X46sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     val_check_interval\u001b[39m=\u001b[39;49mPARAMS[\u001b[39m\"\u001b[39;49m\u001b[39mVAL_CHECK_INTERVAL\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dschr/Coding/nlp/human_value_detector_tmp/human_value_detector/train.ipynb#X46sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     accumulate_grad_batches\u001b[39m=\u001b[39;49mPARAMS[\u001b[39m\"\u001b[39;49m\u001b[39mACCUMULATE_GRAD_BATCHES\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dschr/Coding/nlp/human_value_detector_tmp/human_value_detector/train.ipynb#X46sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\dschr\\Coding\\nlp\\human_value_detector_tmp\\human_value_detector\\.venv\\lib\\site-packages\\pytorch_lightning\\utilities\\argparse.py:339\u001b[0m, in \u001b[0;36m_defaults_from_env_vars.<locals>.insert_env_defaults\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    336\u001b[0m kwargs \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(\u001b[39mlist\u001b[39m(env_variables\u001b[39m.\u001b[39mitems()) \u001b[39m+\u001b[39m \u001b[39mlist\u001b[39m(kwargs\u001b[39m.\u001b[39mitems()))\n\u001b[0;32m    338\u001b[0m \u001b[39m# all args were already moved to kwargs\u001b[39;00m\n\u001b[1;32m--> 339\u001b[0m \u001b[39mreturn\u001b[39;00m fn(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\dschr\\Coding\\nlp\\human_value_detector_tmp\\human_value_detector\\.venv\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:485\u001b[0m, in \u001b[0;36mTrainer.__init__\u001b[1;34m(self, logger, checkpoint_callback, enable_checkpointing, callbacks, default_root_dir, gradient_clip_val, gradient_clip_algorithm, process_position, num_nodes, num_processes, devices, gpus, auto_select_gpus, tpu_cores, ipus, log_gpu_memory, progress_bar_refresh_rate, enable_progress_bar, overfit_batches, track_grad_norm, check_val_every_n_epoch, fast_dev_run, accumulate_grad_batches, max_epochs, min_epochs, max_steps, min_steps, max_time, limit_train_batches, limit_val_batches, limit_test_batches, limit_predict_batches, val_check_interval, flush_logs_every_n_steps, log_every_n_steps, accelerator, strategy, sync_batchnorm, precision, enable_model_summary, weights_summary, weights_save_path, num_sanity_val_steps, resume_from_checkpoint, profiler, benchmark, deterministic, reload_dataloaders_every_n_epochs, auto_lr_find, replace_sampler_ddp, detect_anomaly, auto_scale_batch_size, prepare_data_per_node, plugins, amp_backend, amp_level, move_metrics_to_cpu, multiple_trainloader_mode, stochastic_weight_avg, terminate_on_nan)\u001b[0m\n\u001b[0;32m    482\u001b[0m \u001b[39m# init connectors\u001b[39;00m\n\u001b[0;32m    483\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data_connector \u001b[39m=\u001b[39m DataConnector(\u001b[39mself\u001b[39m, multiple_trainloader_mode)\n\u001b[1;32m--> 485\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_accelerator_connector \u001b[39m=\u001b[39m AcceleratorConnector(\n\u001b[0;32m    486\u001b[0m     num_processes\u001b[39m=\u001b[39;49mnum_processes,\n\u001b[0;32m    487\u001b[0m     devices\u001b[39m=\u001b[39;49mdevices,\n\u001b[0;32m    488\u001b[0m     tpu_cores\u001b[39m=\u001b[39;49mtpu_cores,\n\u001b[0;32m    489\u001b[0m     ipus\u001b[39m=\u001b[39;49mipus,\n\u001b[0;32m    490\u001b[0m     accelerator\u001b[39m=\u001b[39;49maccelerator,\n\u001b[0;32m    491\u001b[0m     strategy\u001b[39m=\u001b[39;49mstrategy,\n\u001b[0;32m    492\u001b[0m     gpus\u001b[39m=\u001b[39;49mgpus,\n\u001b[0;32m    493\u001b[0m     num_nodes\u001b[39m=\u001b[39;49mnum_nodes,\n\u001b[0;32m    494\u001b[0m     sync_batchnorm\u001b[39m=\u001b[39;49msync_batchnorm,\n\u001b[0;32m    495\u001b[0m     benchmark\u001b[39m=\u001b[39;49mbenchmark,\n\u001b[0;32m    496\u001b[0m     replace_sampler_ddp\u001b[39m=\u001b[39;49mreplace_sampler_ddp,\n\u001b[0;32m    497\u001b[0m     deterministic\u001b[39m=\u001b[39;49mdeterministic,\n\u001b[0;32m    498\u001b[0m     auto_select_gpus\u001b[39m=\u001b[39;49mauto_select_gpus,\n\u001b[0;32m    499\u001b[0m     precision\u001b[39m=\u001b[39;49mprecision,\n\u001b[0;32m    500\u001b[0m     amp_type\u001b[39m=\u001b[39;49mamp_backend,\n\u001b[0;32m    501\u001b[0m     amp_level\u001b[39m=\u001b[39;49mamp_level,\n\u001b[0;32m    502\u001b[0m     plugins\u001b[39m=\u001b[39;49mplugins,\n\u001b[0;32m    503\u001b[0m )\n\u001b[0;32m    504\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_logger_connector \u001b[39m=\u001b[39m LoggerConnector(\u001b[39mself\u001b[39m, log_gpu_memory)\n\u001b[0;32m    505\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_callback_connector \u001b[39m=\u001b[39m CallbackConnector(\u001b[39mself\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\dschr\\Coding\\nlp\\human_value_detector_tmp\\human_value_detector\\.venv\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\accelerator_connector.py:201\u001b[0m, in \u001b[0;36mAcceleratorConnector.__init__\u001b[1;34m(self, devices, num_nodes, accelerator, strategy, plugins, precision, amp_type, amp_level, sync_batchnorm, benchmark, replace_sampler_ddp, deterministic, auto_select_gpus, num_processes, tpu_cores, ipus, gpus)\u001b[0m\n\u001b[0;32m    199\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_accelerator_flag \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_accelerator_flag \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    200\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_accelerator_flag \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_choose_accelerator()\n\u001b[1;32m--> 201\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_set_parallel_devices_and_init_accelerator()\n\u001b[0;32m    203\u001b[0m \u001b[39m# 3. Instantiate ClusterEnvironment\u001b[39;00m\n\u001b[0;32m    204\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcluster_environment: ClusterEnvironment \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_choose_and_init_cluster_environment()\n",
      "File \u001b[1;32mc:\\Users\\dschr\\Coding\\nlp\\human_value_detector_tmp\\human_value_detector\\.venv\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\accelerator_connector.py:519\u001b[0m, in \u001b[0;36mAcceleratorConnector._set_parallel_devices_and_init_accelerator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    515\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maccelerator\u001b[39m.\u001b[39mis_available():\n\u001b[0;32m    516\u001b[0m     available_accelerator \u001b[39m=\u001b[39m [\n\u001b[0;32m    517\u001b[0m         acc_str \u001b[39mfor\u001b[39;00m acc_str \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_accelerator_types \u001b[39mif\u001b[39;00m AcceleratorRegistry\u001b[39m.\u001b[39mget(acc_str)\u001b[39m.\u001b[39mis_available()\n\u001b[0;32m    518\u001b[0m     ]\n\u001b[1;32m--> 519\u001b[0m     \u001b[39mraise\u001b[39;00m MisconfigurationException(\n\u001b[0;32m    520\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39maccelerator\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m can not run on your system\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    521\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m since the accelerator is not available. The following accelerator(s)\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    522\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m is available and can be passed into `accelerator` argument of\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    523\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m `Trainer`: \u001b[39m\u001b[39m{\u001b[39;00mavailable_accelerator\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    524\u001b[0m     )\n\u001b[0;32m    526\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_devices_flag_if_auto_passed()\n\u001b[0;32m    528\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_gpus \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_devices_flag \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_gpus \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_gpus\n",
      "\u001b[1;31mMisconfigurationException\u001b[0m: GPUAccelerator can not run on your system since the accelerator is not available. The following accelerator(s) is available and can be passed into `accelerator` argument of `Trainer`: ['cpu']."
     ]
    }
   ],
   "source": [
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=\"checkpoints\",\n",
    "    filename= (f\"{RUN_ID}-{NAME}\" if RUN_ID else f\"{NAME}\"),\n",
    "    save_top_k=1,\n",
    "    verbose=True,\n",
    "    monitor=PARAMS[\"EARLY_STOPPING_METRIC\"],\n",
    "    mode=PARAMS[\"EARLY_STOPPING_MODE\"]\n",
    ")\n",
    "early_stopping_callback = EarlyStopping(monitor=PARAMS[\"EARLY_STOPPING_METRIC\"], patience=PARAMS[\"PATIENCE\"], mode=PARAMS[\"EARLY_STOPPING_MODE\"])\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    logger=([neptune_logger] if RUN_ID else []),\n",
    "    callbacks=[checkpoint_callback, early_stopping_callback],\n",
    "    max_epochs=PARAMS[\"EPOCHS\"],\n",
    "    # fast_dev_run=True,\n",
    "    # accelerator=\"gpu\",\n",
    "    devices=1,\n",
    "    enable_progress_bar=True,\n",
    "    val_check_interval=PARAMS[\"VAL_CHECK_INTERVAL\"],\n",
    "    accumulate_grad_batches=PARAMS[\"ACCUMULATE_GRAD_BATCHES\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dschr\\Coding\\nlp\\human_value_detector_tmp\\human_value_detector\\.venv\\lib\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:639: Checkpoint directory checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type              | Params\n",
      "----------------------------------------------------\n",
      "0 | bert          | RobertaModel      | 124 M \n",
      "1 | hidden_layers | ModuleList        | 0     \n",
      "2 | classifier    | Linear            | 15.4 K\n",
      "3 | criterion     | BCEWithLogitsLoss | 0     \n",
      "----------------------------------------------------\n",
      "124 M     Trainable params\n",
      "0         Non-trainable params\n",
      "124 M     Total params\n",
      "498.644   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dschr\\Coding\\nlp\\human_value_detector_tmp\\human_value_detector\\.venv\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:436: Consider setting `persistent_workers=True` in 'val_dataloader' to speed up the dataloader worker initialization.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0: 100%|██████████| 2/2 [00:00<00:00, 39.36it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dschr\\Coding\\nlp\\human_value_detector_tmp\\human_value_detector\\.venv\\lib\\site-packages\\pytorch_lightning\\core\\module.py:491: You called `self.log('val_loss', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "c:\\Users\\dschr\\Coding\\nlp\\human_value_detector_tmp\\human_value_detector\\.venv\\lib\\site-packages\\pytorch_lightning\\core\\module.py:491: You called `self.log('f1_micro_val_threshold', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "c:\\Users\\dschr\\Coding\\nlp\\human_value_detector_tmp\\human_value_detector\\.venv\\lib\\site-packages\\pytorch_lightning\\core\\module.py:491: You called `self.log('f1_macro_val_threshold', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "c:\\Users\\dschr\\Coding\\nlp\\human_value_detector_tmp\\human_value_detector\\.venv\\lib\\site-packages\\pytorch_lightning\\core\\module.py:491: You called `self.log('f1_custom_val_threshold', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "c:\\Users\\dschr\\Coding\\nlp\\human_value_detector_tmp\\human_value_detector\\.venv\\lib\\site-packages\\pytorch_lightning\\core\\module.py:491: You called `self.log('avg_val_loss', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "c:\\Users\\dschr\\Coding\\nlp\\human_value_detector_tmp\\human_value_detector\\.venv\\lib\\site-packages\\pytorch_lightning\\core\\module.py:491: You called `self.log('Self-direction: thought_precision/Val', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "c:\\Users\\dschr\\Coding\\nlp\\human_value_detector_tmp\\human_value_detector\\.venv\\lib\\site-packages\\pytorch_lightning\\core\\module.py:491: You called `self.log('Self-direction: thought_recall/Val', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "c:\\Users\\dschr\\Coding\\nlp\\human_value_detector_tmp\\human_value_detector\\.venv\\lib\\site-packages\\pytorch_lightning\\core\\module.py:491: You called `self.log('Self-direction: thought_f1-score/Val', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "c:\\Users\\dschr\\Coding\\nlp\\human_value_detector_tmp\\human_value_detector\\.venv\\lib\\site-packages\\pytorch_lightning\\core\\module.py:491: You called `self.log('Self-direction: thought_support/Val', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "c:\\Users\\dschr\\Coding\\nlp\\human_value_detector_tmp\\human_value_detector\\.venv\\lib\\site-packages\\pytorch_lightning\\core\\module.py:491: You called `self.log('Self-direction: action_precision/Val', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "c:\\Users\\dschr\\Coding\\nlp\\human_value_detector_tmp\\human_value_detector\\.venv\\lib\\site-packages\\pytorch_lightning\\core\\module.py:491: You called `self.log('Self-direction: action_recall/Val', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "c:\\Users\\dschr\\Coding\\nlp\\human_value_detector_tmp\\human_value_detector\\.venv\\lib\\site-packages\\pytorch_lightning\\core\\module.py:491: You called `self.log('Self-direction: action_f1-score/Val', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "c:\\Users\\dschr\\Coding\\nlp\\human_value_detector_tmp\\human_value_detector\\.venv\\lib\\site-packages\\pytorch_lightning\\core\\module.py:491: You called `self.log('Self-direction: action_support/Val', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "c:\\Users\\dschr\\Coding\\nlp\\human_value_detector_tmp\\human_value_detector\\.venv\\lib\\site-packages\\pytorch_lightning\\core\\module.py:491: You called `self.log('Stimulation_precision/Val', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "c:\\Users\\dschr\\Coding\\nlp\\human_value_detector_tmp\\human_value_detector\\.venv\\lib\\site-packages\\pytorch_lightning\\core\\module.py:491: You called `self.log('Stimulation_recall/Val', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "c:\\Users\\dschr\\Coding\\nlp\\human_value_detector_tmp\\human_value_detector\\.venv\\lib\\site-packages\\pytorch_lightning\\core\\module.py:491: You called `self.log('Stimulation_f1-score/Val', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "c:\\Users\\dschr\\Coding\\nlp\\human_value_detector_tmp\\human_value_detector\\.venv\\lib\\site-packages\\pytorch_lightning\\core\\module.py:491: You called `self.log('Stimulation_support/Val', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "c:\\Users\\dschr\\Coding\\nlp\\human_value_detector_tmp\\human_value_detector\\.venv\\lib\\site-packages\\pytorch_lightning\\core\\module.py:491: You called `self.log('Hedonism_precision/Val', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "c:\\Users\\dschr\\Coding\\nlp\\human_value_detector_tmp\\human_value_detector\\.venv\\lib\\site-packages\\pytorch_lightning\\core\\module.py:491: You called `self.log('Hedonism_recall/Val', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "c:\\Users\\dschr\\Coding\\nlp\\human_value_detector_tmp\\human_value_detector\\.venv\\lib\\site-packages\\pytorch_lightning\\core\\module.py:491: You called `self.log('Hedonism_f1-score/Val', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "c:\\Users\\dschr\\Coding\\nlp\\human_value_detector_tmp\\human_value_detector\\.venv\\lib\\site-packages\\pytorch_lightning\\core\\module.py:491: You called `self.log('Hedonism_support/Val', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "c:\\Users\\dschr\\Coding\\nlp\\human_value_detector_tmp\\human_value_detector\\.venv\\lib\\site-packages\\pytorch_lightning\\core\\module.py:491: You called `self.log('Achievement_precision/Val', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "c:\\Users\\dschr\\Coding\\nlp\\human_value_detector_tmp\\human_value_detector\\.venv\\lib\\site-packages\\pytorch_lightning\\core\\module.py:491: You called `self.log('Achievement_recall/Val', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "c:\\Users\\dschr\\Coding\\nlp\\human_value_detector_tmp\\human_value_detector\\.venv\\lib\\site-packages\\pytorch_lightning\\core\\module.py:491: You called `self.log('Achievement_f1-score/Val', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "c:\\Users\\dschr\\Coding\\nlp\\human_value_detector_tmp\\human_value_detector\\.venv\\lib\\site-packages\\pytorch_lightning\\core\\module.py:491: You called `self.log('Achievement_support/Val', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "c:\\Users\\dschr\\Coding\\nlp\\human_value_detector_tmp\\human_value_detector\\.venv\\lib\\site-packages\\pytorch_lightning\\core\\module.py:491: You called `self.log('Power: dominance_precision/Val', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "c:\\Users\\dschr\\Coding\\nlp\\human_value_detector_tmp\\human_value_detector\\.venv\\lib\\site-packages\\pytorch_lightning\\core\\module.py:491: You called `self.log('Power: dominance_recall/Val', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "c:\\Users\\dschr\\Coding\\nlp\\human_value_detector_tmp\\human_value_detector\\.venv\\lib\\site-packages\\pytorch_lightning\\core\\module.py:491: You called `self.log('Power: dominance_f1-score/Val', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "c:\\Users\\dschr\\Coding\\nlp\\human_value_detector_tmp\\human_value_detector\\.venv\\lib\\site-packages\\pytorch_lightning\\core\\module.py:491: You called `self.log('Power: dominance_support/Val', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "c:\\Users\\dschr\\Coding\\nlp\\human_value_detector_tmp\\human_value_detector\\.venv\\lib\\site-packages\\pytorch_lightning\\core\\module.py:491: You called `self.log('Power: resources_precision/Val', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "c:\\Users\\dschr\\Coding\\nlp\\human_value_detector_tmp\\human_value_detector\\.venv\\lib\\site-packages\\pytorch_lightning\\core\\module.py:491: You called `self.log('Power: resources_recall/Val', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "c:\\Users\\dschr\\Coding\\nlp\\human_value_detector_tmp\\human_value_detector\\.venv\\lib\\site-packages\\pytorch_lightning\\core\\module.py:491: You called `self.log('Power: resources_f1-score/Val', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "c:\\Users\\dschr\\Coding\\nlp\\human_value_detector_tmp\\human_value_detector\\.venv\\lib\\site-packages\\pytorch_lightning\\core\\module.py:491: You called `self.log('Power: resources_support/Val', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "c:\\Users\\dschr\\Coding\\nlp\\human_value_detector_tmp\\human_value_detector\\.venv\\lib\\site-packages\\pytorch_lightning\\core\\module.py:491: You called `self.log('Face_precision/Val', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "c:\\Users\\dschr\\Coding\\nlp\\human_value_detector_tmp\\human_value_detector\\.venv\\lib\\site-packages\\pytorch_lightning\\core\\module.py:491: You called `self.log('Face_recall/Val', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "c:\\Users\\dschr\\Coding\\nlp\\human_value_detector_tmp\\human_value_detector\\.venv\\lib\\site-packages\\pytorch_lightning\\core\\module.py:491: You called `self.log('Face_f1-score/Val', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "c:\\Users\\dschr\\Coding\\nlp\\human_value_detector_tmp\\human_value_detector\\.venv\\lib\\site-packages\\pytorch_lightning\\core\\module.py:491: You called `self.log('Face_support/Val', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "c:\\Users\\dschr\\Coding\\nlp\\human_value_detector_tmp\\human_value_detector\\.venv\\lib\\site-packages\\pytorch_lightning\\core\\module.py:491: You called `self.log('Security: personal_precision/Val', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "c:\\Users\\dschr\\Coding\\nlp\\human_value_detector_tmp\\human_value_detector\\.venv\\lib\\site-packages\\pytorch_lightning\\core\\module.py:491: You called `self.log('Security: personal_recall/Val', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "c:\\Users\\dschr\\Coding\\nlp\\human_value_detector_tmp\\human_value_detector\\.venv\\lib\\site-packages\\pytorch_lightning\\core\\module.py:491: You called `self.log('Security: personal_f1-score/Val', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "c:\\Users\\dschr\\Coding\\nlp\\human_value_detector_tmp\\human_value_detector\\.venv\\lib\\site-packages\\pytorch_lightning\\core\\module.py:491: You called `self.log('Security: personal_support/Val', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "c:\\Users\\dschr\\Coding\\nlp\\human_value_detector_tmp\\human_value_detector\\.venv\\lib\\site-packages\\pytorch_lightning\\core\\module.py:491: You called `self.log('Security: societal_precision/Val', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "c:\\Users\\dschr\\Coding\\nlp\\human_value_detector_tmp\\human_value_detector\\.venv\\lib\\site-packages\\pytorch_lightning\\core\\module.py:491: You called `self.log('Security: societal_recall/Val', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "c:\\Users\\dschr\\Coding\\nlp\\human_value_detector_tmp\\human_value_detector\\.venv\\lib\\site-packages\\pytorch_lightning\\core\\module.py:491: You called `self.log('Security: societal_f1-score/Val', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "c:\\Users\\dschr\\Coding\\nlp\\human_value_detector_tmp\\human_value_detector\\.venv\\lib\\site-packages\\pytorch_lightning\\core\\module.py:491: You called `self.log('Security: societal_support/Val', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "c:\\Users\\dschr\\Coding\\nlp\\human_value_detector_tmp\\human_value_detector\\.venv\\lib\\site-packages\\pytorch_lightning\\core\\module.py:491: You called `self.log('Tradition_precision/Val', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "c:\\Users\\dschr\\Coding\\nlp\\human_value_detector_tmp\\human_value_detector\\.venv\\lib\\site-packages\\pytorch_lightning\\core\\module.py:491: You called `self.log('Tradition_recall/Val', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "c:\\Users\\dschr\\Coding\\nlp\\human_value_detector_tmp\\human_value_detector\\.venv\\lib\\site-packages\\pytorch_lightning\\core\\module.py:491: You called `self.log('Tradition_f1-score/Val', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "c:\\Users\\dschr\\Coding\\nlp\\human_value_detector_tmp\\human_value_detector\\.venv\\lib\\site-packages\\pytorch_lightning\\core\\module.py:491: You called `self.log('Tradition_support/Val', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "c:\\Users\\dschr\\Coding\\nlp\\human_value_detector_tmp\\human_value_detector\\.venv\\lib\\site-packages\\pytorch_lightning\\core\\module.py:491: You called `self.log('Conformity: rules_precision/Val', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "c:\\Users\\dschr\\Coding\\nlp\\human_value_detector_tmp\\human_value_detector\\.venv\\lib\\site-packages\\pytorch_lightning\\core\\module.py:491: You called `self.log('Conformity: rules_recall/Val', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "c:\\Users\\dschr\\Coding\\nlp\\human_value_detector_tmp\\human_value_detector\\.venv\\lib\\site-packages\\pytorch_lightning\\core\\module.py:491: You called `self.log('Conformity: rules_f1-score/Val', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "c:\\Users\\dschr\\Coding\\nlp\\human_value_detector_tmp\\human_value_detector\\.venv\\lib\\site-packages\\pytorch_lightning\\core\\module.py:491: You called `self.log('Conformity: rules_support/Val', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "c:\\Users\\dschr\\Coding\\nlp\\human_value_detector_tmp\\human_value_detector\\.venv\\lib\\site-packages\\pytorch_lightning\\core\\module.py:491: You called `self.log('Conformity: interpersonal_precision/Val', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "c:\\Users\\dschr\\Coding\\nlp\\human_value_detector_tmp\\human_value_detector\\.venv\\lib\\site-packages\\pytorch_lightning\\core\\module.py:491: You called `self.log('Conformity: interpersonal_recall/Val', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "c:\\Users\\dschr\\Coding\\nlp\\human_value_detector_tmp\\human_value_detector\\.venv\\lib\\site-packages\\pytorch_lightning\\core\\module.py:491: You called `self.log('Conformity: interpersonal_f1-score/Val', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "c:\\Users\\dschr\\Coding\\nlp\\human_value_detector_tmp\\human_value_detector\\.venv\\lib\\site-packages\\pytorch_lightning\\core\\module.py:491: You called `self.log('Conformity: interpersonal_support/Val', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "c:\\Users\\dschr\\Coding\\nlp\\human_value_detector_tmp\\human_value_detector\\.venv\\lib\\site-packages\\pytorch_lightning\\core\\module.py:491: You called `self.log('Humility_precision/Val', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "c:\\Users\\dschr\\Coding\\nlp\\human_value_detector_tmp\\human_value_detector\\.venv\\lib\\site-packages\\pytorch_lightning\\core\\module.py:491: You called `self.log('Humility_recall/Val', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "c:\\Users\\dschr\\Coding\\nlp\\human_value_detector_tmp\\human_value_detector\\.venv\\lib\\site-packages\\pytorch_lightning\\core\\module.py:491: You called `self.log('Humility_f1-score/Val', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "c:\\Users\\dschr\\Coding\\nlp\\human_value_detector_tmp\\human_value_detector\\.venv\\lib\\site-packages\\pytorch_lightning\\core\\module.py:491: You called `self.log('Humility_support/Val', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "c:\\Users\\dschr\\Coding\\nlp\\human_value_detector_tmp\\human_value_detector\\.venv\\lib\\site-packages\\pytorch_lightning\\core\\module.py:491: You called `self.log('Benevolence: caring_precision/Val', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "c:\\Users\\dschr\\Coding\\nlp\\human_value_detector_tmp\\human_value_detector\\.venv\\lib\\site-packages\\pytorch_lightning\\core\\module.py:491: You called `self.log('Benevolence: caring_recall/Val', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "c:\\Users\\dschr\\Coding\\nlp\\human_value_detector_tmp\\human_value_detector\\.venv\\lib\\site-packages\\pytorch_lightning\\core\\module.py:491: You called `self.log('Benevolence: caring_f1-score/Val', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "c:\\Users\\dschr\\Coding\\nlp\\human_value_detector_tmp\\human_value_detector\\.venv\\lib\\site-packages\\pytorch_lightning\\core\\module.py:491: You called `self.log('Benevolence: caring_support/Val', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "c:\\Users\\dschr\\Coding\\nlp\\human_value_detector_tmp\\human_value_detector\\.venv\\lib\\site-packages\\pytorch_lightning\\core\\module.py:491: You called `self.log('Benevolence: dependability_precision/Val', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "c:\\Users\\dschr\\Coding\\nlp\\human_value_detector_tmp\\human_value_detector\\.venv\\lib\\site-packages\\pytorch_lightning\\core\\module.py:491: You called `self.log('Benevolence: dependability_recall/Val', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "c:\\Users\\dschr\\Coding\\nlp\\human_value_detector_tmp\\human_value_detector\\.venv\\lib\\site-packages\\pytorch_lightning\\core\\module.py:491: You called `self.log('Benevolence: dependability_f1-score/Val', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "c:\\Users\\dschr\\Coding\\nlp\\human_value_detector_tmp\\human_value_detector\\.venv\\lib\\site-packages\\pytorch_lightning\\core\\module.py:491: You called `self.log('Benevolence: dependability_support/Val', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "c:\\Users\\dschr\\Coding\\nlp\\human_value_detector_tmp\\human_value_detector\\.venv\\lib\\site-packages\\pytorch_lightning\\core\\module.py:491: You called `self.log('Universalism: concern_precision/Val', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "c:\\Users\\dschr\\Coding\\nlp\\human_value_detector_tmp\\human_value_detector\\.venv\\lib\\site-packages\\pytorch_lightning\\core\\module.py:491: You called `self.log('Universalism: concern_recall/Val', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "c:\\Users\\dschr\\Coding\\nlp\\human_value_detector_tmp\\human_value_detector\\.venv\\lib\\site-packages\\pytorch_lightning\\core\\module.py:491: You called `self.log('Universalism: concern_f1-score/Val', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "c:\\Users\\dschr\\Coding\\nlp\\human_value_detector_tmp\\human_value_detector\\.venv\\lib\\site-packages\\pytorch_lightning\\core\\module.py:491: You called `self.log('Universalism: concern_support/Val', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "c:\\Users\\dschr\\Coding\\nlp\\human_value_detector_tmp\\human_value_detector\\.venv\\lib\\site-packages\\pytorch_lightning\\core\\module.py:491: You called `self.log('Universalism: nature_precision/Val', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "c:\\Users\\dschr\\Coding\\nlp\\human_value_detector_tmp\\human_value_detector\\.venv\\lib\\site-packages\\pytorch_lightning\\core\\module.py:491: You called `self.log('Universalism: nature_recall/Val', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "c:\\Users\\dschr\\Coding\\nlp\\human_value_detector_tmp\\human_value_detector\\.venv\\lib\\site-packages\\pytorch_lightning\\core\\module.py:491: You called `self.log('Universalism: nature_f1-score/Val', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "c:\\Users\\dschr\\Coding\\nlp\\human_value_detector_tmp\\human_value_detector\\.venv\\lib\\site-packages\\pytorch_lightning\\core\\module.py:491: You called `self.log('Universalism: nature_support/Val', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "c:\\Users\\dschr\\Coding\\nlp\\human_value_detector_tmp\\human_value_detector\\.venv\\lib\\site-packages\\pytorch_lightning\\core\\module.py:491: You called `self.log('Universalism: tolerance_precision/Val', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "c:\\Users\\dschr\\Coding\\nlp\\human_value_detector_tmp\\human_value_detector\\.venv\\lib\\site-packages\\pytorch_lightning\\core\\module.py:491: You called `self.log('Universalism: tolerance_recall/Val', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "c:\\Users\\dschr\\Coding\\nlp\\human_value_detector_tmp\\human_value_detector\\.venv\\lib\\site-packages\\pytorch_lightning\\core\\module.py:491: You called `self.log('Universalism: tolerance_f1-score/Val', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "c:\\Users\\dschr\\Coding\\nlp\\human_value_detector_tmp\\human_value_detector\\.venv\\lib\\site-packages\\pytorch_lightning\\core\\module.py:491: You called `self.log('Universalism: tolerance_support/Val', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "c:\\Users\\dschr\\Coding\\nlp\\human_value_detector_tmp\\human_value_detector\\.venv\\lib\\site-packages\\pytorch_lightning\\core\\module.py:491: You called `self.log('Universalism: objectivity_precision/Val', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "c:\\Users\\dschr\\Coding\\nlp\\human_value_detector_tmp\\human_value_detector\\.venv\\lib\\site-packages\\pytorch_lightning\\core\\module.py:491: You called `self.log('Universalism: objectivity_recall/Val', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "c:\\Users\\dschr\\Coding\\nlp\\human_value_detector_tmp\\human_value_detector\\.venv\\lib\\site-packages\\pytorch_lightning\\core\\module.py:491: You called `self.log('Universalism: objectivity_f1-score/Val', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "c:\\Users\\dschr\\Coding\\nlp\\human_value_detector_tmp\\human_value_detector\\.venv\\lib\\site-packages\\pytorch_lightning\\core\\module.py:491: You called `self.log('Universalism: objectivity_support/Val', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "c:\\Users\\dschr\\Coding\\nlp\\human_value_detector_tmp\\human_value_detector\\.venv\\lib\\site-packages\\pytorch_lightning\\core\\module.py:491: You called `self.log('micro avg_precision/Val', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "c:\\Users\\dschr\\Coding\\nlp\\human_value_detector_tmp\\human_value_detector\\.venv\\lib\\site-packages\\pytorch_lightning\\core\\module.py:491: You called `self.log('micro avg_recall/Val', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "c:\\Users\\dschr\\Coding\\nlp\\human_value_detector_tmp\\human_value_detector\\.venv\\lib\\site-packages\\pytorch_lightning\\core\\module.py:491: You called `self.log('micro avg_f1-score/Val', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "c:\\Users\\dschr\\Coding\\nlp\\human_value_detector_tmp\\human_value_detector\\.venv\\lib\\site-packages\\pytorch_lightning\\core\\module.py:491: You called `self.log('micro avg_support/Val', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "c:\\Users\\dschr\\Coding\\nlp\\human_value_detector_tmp\\human_value_detector\\.venv\\lib\\site-packages\\pytorch_lightning\\core\\module.py:491: You called `self.log('custom_f1/Val', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "c:\\Users\\dschr\\Coding\\nlp\\human_value_detector_tmp\\human_value_detector\\.venv\\lib\\site-packages\\pytorch_lightning\\core\\module.py:491: You called `self.log('macro avg_precision/Val', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "c:\\Users\\dschr\\Coding\\nlp\\human_value_detector_tmp\\human_value_detector\\.venv\\lib\\site-packages\\pytorch_lightning\\core\\module.py:491: You called `self.log('macro avg_recall/Val', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "c:\\Users\\dschr\\Coding\\nlp\\human_value_detector_tmp\\human_value_detector\\.venv\\lib\\site-packages\\pytorch_lightning\\core\\module.py:491: You called `self.log('macro avg_f1-score/Val', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "c:\\Users\\dschr\\Coding\\nlp\\human_value_detector_tmp\\human_value_detector\\.venv\\lib\\site-packages\\pytorch_lightning\\core\\module.py:491: You called `self.log('macro avg_support/Val', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "c:\\Users\\dschr\\Coding\\nlp\\human_value_detector_tmp\\human_value_detector\\.venv\\lib\\site-packages\\pytorch_lightning\\core\\module.py:491: You called `self.log('weighted avg_precision/Val', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "c:\\Users\\dschr\\Coding\\nlp\\human_value_detector_tmp\\human_value_detector\\.venv\\lib\\site-packages\\pytorch_lightning\\core\\module.py:491: You called `self.log('weighted avg_recall/Val', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "c:\\Users\\dschr\\Coding\\nlp\\human_value_detector_tmp\\human_value_detector\\.venv\\lib\\site-packages\\pytorch_lightning\\core\\module.py:491: You called `self.log('weighted avg_f1-score/Val', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "c:\\Users\\dschr\\Coding\\nlp\\human_value_detector_tmp\\human_value_detector\\.venv\\lib\\site-packages\\pytorch_lightning\\core\\module.py:491: You called `self.log('weighted avg_support/Val', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "c:\\Users\\dschr\\Coding\\nlp\\human_value_detector_tmp\\human_value_detector\\.venv\\lib\\site-packages\\pytorch_lightning\\core\\module.py:491: You called `self.log('samples avg_precision/Val', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "c:\\Users\\dschr\\Coding\\nlp\\human_value_detector_tmp\\human_value_detector\\.venv\\lib\\site-packages\\pytorch_lightning\\core\\module.py:491: You called `self.log('samples avg_recall/Val', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "c:\\Users\\dschr\\Coding\\nlp\\human_value_detector_tmp\\human_value_detector\\.venv\\lib\\site-packages\\pytorch_lightning\\core\\module.py:491: You called `self.log('samples avg_f1-score/Val', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "c:\\Users\\dschr\\Coding\\nlp\\human_value_detector_tmp\\human_value_detector\\.venv\\lib\\site-packages\\pytorch_lightning\\core\\module.py:491: You called `self.log('samples avg_support/Val', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "c:\\Users\\dschr\\Coding\\nlp\\human_value_detector_tmp\\human_value_detector\\.venv\\lib\\site-packages\\pytorch_lightning\\core\\module.py:491: You called `self.log('Self-direction: thought_roc_auc/Val', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "c:\\Users\\dschr\\Coding\\nlp\\human_value_detector_tmp\\human_value_detector\\.venv\\lib\\site-packages\\pytorch_lightning\\core\\module.py:491: You called `self.log('Self-direction: action_roc_auc/Val', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "c:\\Users\\dschr\\Coding\\nlp\\human_value_detector_tmp\\human_value_detector\\.venv\\lib\\site-packages\\pytorch_lightning\\core\\module.py:491: You called `self.log('Stimulation_roc_auc/Val', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "c:\\Users\\dschr\\Coding\\nlp\\human_value_detector_tmp\\human_value_detector\\.venv\\lib\\site-packages\\torchmetrics\\utilities\\prints.py:36: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "c:\\Users\\dschr\\Coding\\nlp\\human_value_detector_tmp\\human_value_detector\\.venv\\lib\\site-packages\\pytorch_lightning\\core\\module.py:491: You called `self.log('Hedonism_roc_auc/Val', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "c:\\Users\\dschr\\Coding\\nlp\\human_value_detector_tmp\\human_value_detector\\.venv\\lib\\site-packages\\pytorch_lightning\\core\\module.py:491: You called `self.log('Achievement_roc_auc/Val', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "c:\\Users\\dschr\\Coding\\nlp\\human_value_detector_tmp\\human_value_detector\\.venv\\lib\\site-packages\\pytorch_lightning\\core\\module.py:491: You called `self.log('Power: dominance_roc_auc/Val', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "c:\\Users\\dschr\\Coding\\nlp\\human_value_detector_tmp\\human_value_detector\\.venv\\lib\\site-packages\\pytorch_lightning\\core\\module.py:491: You called `self.log('Power: resources_roc_auc/Val', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "c:\\Users\\dschr\\Coding\\nlp\\human_value_detector_tmp\\human_value_detector\\.venv\\lib\\site-packages\\pytorch_lightning\\core\\module.py:491: You called `self.log('Face_roc_auc/Val', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "c:\\Users\\dschr\\Coding\\nlp\\human_value_detector_tmp\\human_value_detector\\.venv\\lib\\site-packages\\pytorch_lightning\\core\\module.py:491: You called `self.log('Security: personal_roc_auc/Val', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "c:\\Users\\dschr\\Coding\\nlp\\human_value_detector_tmp\\human_value_detector\\.venv\\lib\\site-packages\\pytorch_lightning\\core\\module.py:491: You called `self.log('Security: societal_roc_auc/Val', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "c:\\Users\\dschr\\Coding\\nlp\\human_value_detector_tmp\\human_value_detector\\.venv\\lib\\site-packages\\pytorch_lightning\\core\\module.py:491: You called `self.log('Tradition_roc_auc/Val', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "c:\\Users\\dschr\\Coding\\nlp\\human_value_detector_tmp\\human_value_detector\\.venv\\lib\\site-packages\\pytorch_lightning\\core\\module.py:491: You called `self.log('Conformity: rules_roc_auc/Val', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "c:\\Users\\dschr\\Coding\\nlp\\human_value_detector_tmp\\human_value_detector\\.venv\\lib\\site-packages\\pytorch_lightning\\core\\module.py:491: You called `self.log('Conformity: interpersonal_roc_auc/Val', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "c:\\Users\\dschr\\Coding\\nlp\\human_value_detector_tmp\\human_value_detector\\.venv\\lib\\site-packages\\pytorch_lightning\\core\\module.py:491: You called `self.log('Humility_roc_auc/Val', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "c:\\Users\\dschr\\Coding\\nlp\\human_value_detector_tmp\\human_value_detector\\.venv\\lib\\site-packages\\pytorch_lightning\\core\\module.py:491: You called `self.log('Benevolence: caring_roc_auc/Val', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "c:\\Users\\dschr\\Coding\\nlp\\human_value_detector_tmp\\human_value_detector\\.venv\\lib\\site-packages\\pytorch_lightning\\core\\module.py:491: You called `self.log('Benevolence: dependability_roc_auc/Val', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "c:\\Users\\dschr\\Coding\\nlp\\human_value_detector_tmp\\human_value_detector\\.venv\\lib\\site-packages\\pytorch_lightning\\core\\module.py:491: You called `self.log('Universalism: concern_roc_auc/Val', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "c:\\Users\\dschr\\Coding\\nlp\\human_value_detector_tmp\\human_value_detector\\.venv\\lib\\site-packages\\pytorch_lightning\\core\\module.py:491: You called `self.log('Universalism: nature_roc_auc/Val', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "c:\\Users\\dschr\\Coding\\nlp\\human_value_detector_tmp\\human_value_detector\\.venv\\lib\\site-packages\\pytorch_lightning\\core\\module.py:491: You called `self.log('Universalism: tolerance_roc_auc/Val', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "c:\\Users\\dschr\\Coding\\nlp\\human_value_detector_tmp\\human_value_detector\\.venv\\lib\\site-packages\\pytorch_lightning\\core\\module.py:491: You called `self.log('Universalism: objectivity_roc_auc/Val', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "c:\\Users\\dschr\\Coding\\nlp\\human_value_detector_tmp\\human_value_detector\\.venv\\lib\\site-packages\\pytorch_lightning\\core\\module.py:491: You called `self.log('roc_auc_total_micro/Val', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "c:\\Users\\dschr\\Coding\\nlp\\human_value_detector_tmp\\human_value_detector\\.venv\\lib\\site-packages\\pytorch_lightning\\core\\module.py:491: You called `self.log('roc_auc_total_macro/Val', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dschr\\Coding\\nlp\\human_value_detector_tmp\\human_value_detector\\.venv\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:436: Consider setting `persistent_workers=True` in 'train_dataloader' to speed up the dataloader worker initialization.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/797 [00:00<?, ?it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dschr\\Coding\\nlp\\human_value_detector_tmp\\human_value_detector\\.venv\\lib\\site-packages\\pytorch_lightning\\core\\module.py:491: You called `self.log('train_loss', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  14%|█▍        | 115/797 [02:37<15:36,  0.73it/s, train_loss=0.416]"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "trainer.fit(model, data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if RUN_ID:\n",
    "    with open(f\"./checkpoints/{RUN_ID}_PARAMS.pkl\", 'wb') as f:\n",
    "        pickle.dump(PARAMS, f)\n",
    "else:\n",
    "    with open(f\"./checkpoints/{NAME}_PARAMS.pkl\", 'wb') as f:\n",
    "        pickle.dump(PARAMS, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# If Logging (optional)\n",
    "neptune_logger.experiment[\"best_model_checkpoint\"].log(trainer.checkpoint_callback.best_model_path)\n",
    "neptune_logger.log_model_summary(model=model, max_depth=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Now we are done with the training. This process is repeated with several different configurations for the model. More information can be found in the system description paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Evaluation\n",
    "\n",
    "The predictions for the final submissions are done based on an ensemble.\n",
    "Hence for ensembling, please continue with the ensemble_eval_and_predict.ipynb notebook.\n",
    "However, for simplicity or if you are interested, you may want to continue here to evaluate the model performance.\n",
    "\n",
    "1. We determine the decision threshold to decide when a certain label should be counted as 1, based on the val_data\n",
    "2. We predict the test_data with it (if splitted above)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We load the model from the best_checkpoint in order to get the model that performed best with respect to the early stopping metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trained_model = BertFineTunerPl.load_from_checkpoint(\n",
    "    trainer.checkpoint_callback.best_model_path,\n",
    "    params=PARAMS,\n",
    "    label_columns=LABEL_COLUMNS,\n",
    "    n_classes=len(LABEL_COLUMNS)\n",
    ")\n",
    "\n",
    "trained_model.eval()\n",
    "trained_model.freeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We get the predictions for the val_df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a3e04f3307d49b9bb126199c8beac4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "trained_model = trained_model.to(device)\n",
    "\n",
    "val_dataset = BertDataset(\n",
    "    val_df,\n",
    "    tokenizer=TOKENIZER,\n",
    "    max_token_count=PARAMS[\"MAX_TOKEN_COUNT\"],\n",
    "    label_columns=LABEL_COLUMNS\n",
    ")\n",
    "\n",
    "predictions = []\n",
    "labels = []\n",
    "\n",
    "for item in tqdm(val_dataset):\n",
    "    _, prediction = trained_model(\n",
    "        item[\"input_ids\"].unsqueeze(dim=0).to(device),\n",
    "        item[\"attention_mask\"].unsqueeze(dim=0).to(device)\n",
    "    )\n",
    "    predictions.append(prediction.flatten())\n",
    "    labels.append(item[\"labels\"].int())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Select optimal Threshold on Val Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = torch.stack(predictions).detach().cpu()\n",
    "labels = torch.stack(labels).detach().cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from toolbox.bert_utils import max_for_thres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "THRESHOLD = max_for_thres(y_pred=predictions, y_true=labels, label_columns=LABEL_COLUMNS, average=PARAMS[\"MAX_THRESHOLD_METRIC\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Alternatively if you just one to load a model from checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-large were not used when initializing DebertaModel: ['lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.bias']\n",
      "- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "with open(f'./checkpoints/HCV-409_PARAMS.pkl', 'rb') as f:\n",
    "    loaded_dict = pickle.load(f)\n",
    "    PARAMS = loaded_dict\n",
    "\n",
    "trained_model = BertFineTunerPl.load_from_checkpoint(\n",
    "    \"./checkpoints/HCV-409-microsoft-deberta-large-BS_8-LR_2e-05-HL_None-DROPOUT_None-SL_None.ckpt\",\n",
    "    params=PARAMS,\n",
    "    label_columns=LABEL_COLUMNS,\n",
    "    n_classes=len(LABEL_COLUMNS)\n",
    ")\n",
    "\n",
    "trained_model.eval()\n",
    "trained_model.freeze()\n",
    "\n",
    "THRESHOLD = 0.25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "binarize the predictions with the optimal threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred = predictions.numpy()\n",
    "y_true = labels.numpy()\n",
    "\n",
    "upper, lower = 1, 0\n",
    "\n",
    "y_pred = np.where(y_pred > THRESHOLD, upper, lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(f\"Threshold: {THRESHOLD}\")\n",
    "print(classification_report(\n",
    "    y_true,\n",
    "    y_pred,\n",
    "    target_names=LABEL_COLUMNS,\n",
    "    zero_division=0,\n",
    "))\n",
    "\n",
    "class_rep = classification_report(\n",
    "    y_true,\n",
    "    y_pred,\n",
    "    target_names=LABEL_COLUMNS,\n",
    "    zero_division=0,\n",
    "    output_dict=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Use Threshold to predict on Test Data\n",
    "If we want to predict on the test-data (if you have split it apart, alternatively you could use the leave-out-dataset). For a single Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_df = leave_out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "trained_model = trained_model.to(device)\n",
    "\n",
    "test_dataset = BertDataset(\n",
    "    test_df,\n",
    "    tokenizer=TOKENIZER,\n",
    "    max_token_count=PARAMS[\"MAX_TOKEN_COUNT\"],\n",
    "    label_columns=LABEL_COLUMNS\n",
    ")\n",
    "\n",
    "predictions = []\n",
    "labels = []\n",
    "\n",
    "for item in tqdm(test_dataset):\n",
    "    _, prediction = trained_model(\n",
    "        item[\"input_ids\"].unsqueeze(dim=0).to(device),\n",
    "        item[\"attention_mask\"].unsqueeze(dim=0).to(device)\n",
    "    )\n",
    "    predictions.append(prediction.flatten())\n",
    "    labels.append(item[\"labels\"].int())\n",
    "\n",
    "\n",
    "predictions = torch.stack(predictions).detach().cpu()\n",
    "labels = torch.stack(labels).detach().cpu()\n",
    "\n",
    "\n",
    "y_pred = predictions.numpy()\n",
    "y_true = labels.numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "###  Binarize the model predictions with Threshold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "upper, lower = 1, 0\n",
    "\n",
    "y_pred = np.where(y_pred > THRESHOLD, upper, lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.25\n",
      "                            precision    recall  f1-score   support\n",
      "\n",
      "   Self-direction: thought       0.41      0.92      0.57        49\n",
      "    Self-direction: action       0.69      0.89      0.78        75\n",
      "               Stimulation       0.19      0.64      0.29        14\n",
      "                  Hedonism       0.20      1.00      0.33         5\n",
      "               Achievement       0.74      0.92      0.82        86\n",
      "          Power: dominance       0.39      0.91      0.55        33\n",
      "          Power: resources       0.50      1.00      0.67        26\n",
      "                      Face       0.24      0.56      0.34        25\n",
      "        Security: personal       0.71      0.95      0.81       103\n",
      "        Security: societal       0.69      0.94      0.80        85\n",
      "                 Tradition       0.54      1.00      0.70        31\n",
      "         Conformity: rules       0.75      0.91      0.82        81\n",
      " Conformity: interpersonal       0.33      0.82      0.47        11\n",
      "                  Humility       0.37      1.00      0.54        13\n",
      "       Benevolence: caring       0.43      0.91      0.59        74\n",
      "Benevolence: dependability       0.34      0.71      0.46        42\n",
      "     Universalism: concern       0.66      0.94      0.77       125\n",
      "      Universalism: nature       0.50      0.88      0.64        17\n",
      "   Universalism: tolerance       0.25      0.65      0.36        34\n",
      " Universalism: objectivity       0.48      0.84      0.61        61\n",
      "\n",
      "                 micro avg       0.52      0.89      0.66       990\n",
      "                 macro avg       0.47      0.87      0.60       990\n",
      "              weighted avg       0.57      0.89      0.68       990\n",
      "               samples avg       0.56      0.91      0.66       990\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Threshold: {THRESHOLD}\")\n",
    "print(classification_report(\n",
    "    y_true,\n",
    "    y_pred,\n",
    "    target_names=LABEL_COLUMNS,\n",
    "    zero_division=0,\n",
    "))\n",
    "\n",
    "class_rep = classification_report(\n",
    "    y_true,\n",
    "    y_pred,\n",
    "    target_names=LABEL_COLUMNS,\n",
    "    zero_division=0,\n",
    "    output_dict=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Logging Optional\n",
    "neptune_logger.experiment[f\"threshold_selected_for_f1_custom_val_opt\"].log(THRESHOLD)\n",
    "\n",
    "for k in class_rep:\n",
    "    neptune_logger.experiment[f\"{k}_precision/Test\"].log(class_rep[k][\"precision\"])\n",
    "    neptune_logger.experiment[f\"{k}_recall/Test\"].log(class_rep[k][\"recall\"])\n",
    "    neptune_logger.experiment[f\"{k}_f1-score/Test\"].log(class_rep[k][\"f1-score\"])\n",
    "    neptune_logger.experiment[f\"{k}_support/Test\"].log(class_rep[k][\"support\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate F1-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6105788216966658\n"
     ]
    }
   ],
   "source": [
    "test_custom_f1 = -1\n",
    "test_macro_recall = class_rep[\"macro avg\"][\"recall\"]\n",
    "test_macro_precision = class_rep[\"macro avg\"][\"precision\"]\n",
    "if (test_macro_precision + test_macro_recall) != 0:\n",
    "    test_custom_f1 = (2*test_macro_recall*test_macro_precision/(test_macro_recall+test_macro_precision))\n",
    "else:\n",
    "    test_custom_f1 = 0\n",
    "print(test_custom_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Optionally Log\n",
    "\n",
    "for i, name in enumerate(LABEL_COLUMNS):\n",
    "    auroc = AUROC(task=\"binary\")\n",
    "    class_roc_auc = auroc(predictions[:, i], labels[:, i])\n",
    "    # neptune_logger.experiment[f\"{name}_roc_auc/Test\"].log(class_roc_auc)\n",
    "\n",
    "auroc = AUROC(task=\"multilabel\", num_labels=len(LABEL_COLUMNS), average=\"micro\")\n",
    "total_auroc_micro = auroc(predictions, labels)\n",
    "\n",
    "auroc = AUROC(task=\"multilabel\", num_labels=len(LABEL_COLUMNS), average=\"macro\")\n",
    "total_auroc_macro = auroc(predictions, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Log Metrics Optionally\n",
    "neptune_logger.experiment[f\"custom_f1/Test\"].log(test_custom_f1)\n",
    "neptune_logger.experiment[f\"roc_auc_total_macro/Test\"].log(total_auroc_macro)\n",
    "neptune_logger.experiment[f\"roc_auc_total_micro/Test\"].log(total_auroc_micro)\n",
    "neptune_logger.experiment.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hFvqzK4Ua-16"
   },
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Submission File\n",
    "Creating the submission file for one Model for the competition. (Note that the submitted systems are ensembles (ensemble_eval_and_predict.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_input = pd.read_csv('./data/arguments-test.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Argument ID</th>\n",
       "      <th>Conclusion</th>\n",
       "      <th>Stance</th>\n",
       "      <th>Premise</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A26004</td>\n",
       "      <td>We should end affirmative action</td>\n",
       "      <td>against</td>\n",
       "      <td>affirmative action helps with employment equity.</td>\n",
       "      <td>affirmative action helps with employment equit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A26010</td>\n",
       "      <td>We should end affirmative action</td>\n",
       "      <td>in favor of</td>\n",
       "      <td>affirmative action can be considered discrimin...</td>\n",
       "      <td>affirmative action can be considered discrimin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A26016</td>\n",
       "      <td>We should ban naturopathy</td>\n",
       "      <td>in favor of</td>\n",
       "      <td>naturopathy is very dangerous for the most vul...</td>\n",
       "      <td>naturopathy is very dangerous for the most vul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A26024</td>\n",
       "      <td>We should prohibit women in combat</td>\n",
       "      <td>in favor of</td>\n",
       "      <td>women shouldn't be in combat because they aren...</td>\n",
       "      <td>women shouldn't be in combat because they aren...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A26026</td>\n",
       "      <td>We should ban naturopathy</td>\n",
       "      <td>in favor of</td>\n",
       "      <td>once eradicated illnesses are returning due to...</td>\n",
       "      <td>once eradicated illnesses are returning due to...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Argument ID                          Conclusion       Stance  \\\n",
       "0      A26004    We should end affirmative action      against   \n",
       "1      A26010    We should end affirmative action  in favor of   \n",
       "2      A26016           We should ban naturopathy  in favor of   \n",
       "3      A26024  We should prohibit women in combat  in favor of   \n",
       "4      A26026           We should ban naturopathy  in favor of   \n",
       "\n",
       "                                             Premise  \\\n",
       "0   affirmative action helps with employment equity.   \n",
       "1  affirmative action can be considered discrimin...   \n",
       "2  naturopathy is very dangerous for the most vul...   \n",
       "3  women shouldn't be in combat because they aren...   \n",
       "4  once eradicated illnesses are returning due to...   \n",
       "\n",
       "                                                text  \n",
       "0  affirmative action helps with employment equit...  \n",
       "1  affirmative action can be considered discrimin...  \n",
       "2  naturopathy is very dangerous for the most vul...  \n",
       "3  women shouldn't be in combat because they aren...  \n",
       "4  once eradicated illnesses are returning due to...  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df_input[\"text\"] = test_df_input[\"Premise\"]+\" \" + test_df_input[\"Stance\"]+ \" \" + test_df_input[\"Conclusion\"]\n",
    "test_df_input.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "trained_model = trained_model.to(device)\n",
    "\n",
    "test_df_dataset = BertDataset(\n",
    "    data=test_df_input,\n",
    "    tokenizer=TOKENIZER,\n",
    "    max_token_count=PARAMS[\"MAX_TOKEN_COUNT\"],\n",
    ")\n",
    "\n",
    "predictions = []\n",
    "\n",
    "for item in tqdm(test_df_dataset):\n",
    "    _, prediction = trained_model(\n",
    "        item[\"input_ids\"].unsqueeze(dim=0).to(device),\n",
    "        item[\"attention_mask\"].unsqueeze(dim=0).to(device)\n",
    "    )\n",
    "    predictions.append(prediction.flatten())\n",
    "\n",
    "predictions = torch.stack(predictions).detach().cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = predictions.numpy()\n",
    "upper, lower = 1, 0\n",
    "y_pred = np.where(y_pred > THRESHOLD, upper, lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Argument ID</th>\n",
       "      <th>Self-direction: thought</th>\n",
       "      <th>Self-direction: action</th>\n",
       "      <th>Stimulation</th>\n",
       "      <th>Hedonism</th>\n",
       "      <th>Achievement</th>\n",
       "      <th>Power: dominance</th>\n",
       "      <th>Power: resources</th>\n",
       "      <th>Face</th>\n",
       "      <th>Security: personal</th>\n",
       "      <th>...</th>\n",
       "      <th>Tradition</th>\n",
       "      <th>Conformity: rules</th>\n",
       "      <th>Conformity: interpersonal</th>\n",
       "      <th>Humility</th>\n",
       "      <th>Benevolence: caring</th>\n",
       "      <th>Benevolence: dependability</th>\n",
       "      <th>Universalism: concern</th>\n",
       "      <th>Universalism: nature</th>\n",
       "      <th>Universalism: tolerance</th>\n",
       "      <th>Universalism: objectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A26004</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A26010</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A26016</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A26024</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A26026</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Argument ID  Self-direction: thought  Self-direction: action  Stimulation  \\\n",
       "0      A26004                        0                       0            0   \n",
       "1      A26010                        0                       0            0   \n",
       "2      A26016                        0                       0            0   \n",
       "3      A26024                        0                       0            0   \n",
       "4      A26026                        0                       0            0   \n",
       "\n",
       "   Hedonism  Achievement  Power: dominance  Power: resources  Face  \\\n",
       "0         0            1                 0                 0     0   \n",
       "1         0            0                 0                 0     0   \n",
       "2         0            1                 0                 0     0   \n",
       "3         0            1                 0                 0     0   \n",
       "4         0            0                 0                 0     0   \n",
       "\n",
       "   Security: personal  ...  Tradition  Conformity: rules  \\\n",
       "0                   1  ...          0                  0   \n",
       "1                   0  ...          0                  0   \n",
       "2                   1  ...          0                  0   \n",
       "3                   0  ...          0                  0   \n",
       "4                   1  ...          0                  0   \n",
       "\n",
       "   Conformity: interpersonal  Humility  Benevolence: caring  \\\n",
       "0                          0         0                    0   \n",
       "1                          0         0                    0   \n",
       "2                          0         0                    1   \n",
       "3                          0         0                    0   \n",
       "4                          0         0                    0   \n",
       "\n",
       "   Benevolence: dependability  Universalism: concern  Universalism: nature  \\\n",
       "0                           0                      1                     0   \n",
       "1                           0                      1                     0   \n",
       "2                           0                      1                     0   \n",
       "3                           0                      1                     0   \n",
       "4                           0                      0                     0   \n",
       "\n",
       "   Universalism: tolerance  Universalism: objectivity  \n",
       "0                        0                          0  \n",
       "1                        1                          0  \n",
       "2                        0                          1  \n",
       "3                        0                          0  \n",
       "4                        0                          1  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_dictionary = {}\n",
    "prediction_dictionary[\"Argument ID\"] = test_df_input[\"Argument ID\"]\n",
    "for idx, l_name in enumerate(LABEL_COLUMNS):\n",
    "  prediction_dictionary[l_name]=y_pred[:,idx]\n",
    "\n",
    "test_prediction_df = pd.DataFrame(prediction_dictionary)\n",
    "test_prediction_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_ID:\n",
    "    test_prediction_df.to_csv(f\"submissions/{RUN_ID}-submission_test.txt\", sep=\"\\t\", index=False)\n",
    "else:\n",
    "    test_prediction_df.to_csv(f\"submissions/{NAME}-submission_test.txt\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Looking at single predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_example_prediction(record, show_all_probs=False, THRESHOLD=0.3):\n",
    "\n",
    "    print(record[\"Argument ID\"])\n",
    "    print(record[\"text\"])\n",
    "    print(f\"True Label: {record.category}\")\n",
    "\n",
    "\n",
    "    encoding = TOKENIZER.encode_plus(\n",
    "        record.text,\n",
    "        add_special_tokens=True,\n",
    "        max_length=512,\n",
    "        return_token_type_ids=False,\n",
    "        padding=\"max_length\",\n",
    "        return_attention_mask=True,\n",
    "        return_tensors='pt',\n",
    "    )\n",
    "\n",
    "    _, test_prediction = trained_model(encoding[\"input_ids\"], encoding[\"attention_mask\"])\n",
    "    test_prediction = test_prediction.flatten().numpy()\n",
    "\n",
    "    res = {}\n",
    "    if show_all_probs:\n",
    "        for label, prediction in zip(LABEL_COLUMNS, test_prediction):\n",
    "            print(f\"{label}: {prediction}\")\n",
    "            res[label] = prediction\n",
    "\n",
    "    else:\n",
    "        print(f\"Predictions:\")\n",
    "        for label, prediction in zip(LABEL_COLUMNS, test_prediction):\n",
    "            if prediction < THRESHOLD:\n",
    "                continue\n",
    "            print(f\"{label}: {prediction}\")\n",
    "            res[label] = prediction\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A18309\n",
      "social media gives it users a place to seek support when in need whether emotional or financially, things that would be more difficult if not impossible to do outside of their home. against Social media brings more harm than good\n",
      "True Label: ['Self-direction: action', 'Face', 'Security: personal', 'Benevolence: caring', 'Benevolence: dependability']\n",
      "Predictions:\n",
      "Self-direction: action: 0.49473991990089417\n",
      "Stimulation: 0.40371981263160706\n",
      "Hedonism: 0.4516661763191223\n",
      "Security: personal: 0.9821780323982239\n",
      "Benevolence: caring: 0.9349980354309082\n",
      "Universalism: tolerance: 0.327671617269516\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Self-direction: action': 0.49473992,\n",
       " 'Stimulation': 0.4037198,\n",
       " 'Hedonism': 0.45166618,\n",
       " 'Security: personal': 0.98217803,\n",
       " 'Benevolence: caring': 0.93499804,\n",
       " 'Universalism: tolerance': 0.32767162}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 13 whaling is good one\n",
    "trained_model.to(\"cpu\")\n",
    "test_record = test_df.iloc[6]\n",
    "print_example_prediction(test_record, show_all_probs=False, THRESHOLD=THRESHOLD)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": [
    {
     "file_id": "14Ea4lIzsn5EFvPpYKtWStXEByT9qmbkj",
     "timestamp": 1667212470973
    }
   ]
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
